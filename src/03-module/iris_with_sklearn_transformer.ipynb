{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2kLrOh-bpGy"
   },
   "source": [
    "# Iris Flower Classification with Scikit-Learn and Hopsworks\n",
    "\n",
    "In this notebook we will, \n",
    "\n",
    "1. Import libraries and connect to Hopsworks Feature Store\n",
    "2. Load the iris Flower dataset\n",
    "3. Create a feature group and upload to the feature store\n",
    "4. Create a feature view from the feature group\n",
    "5. Create a training dataset\n",
    "6. Train a model using SkLearn\n",
    "7. Save the trained model to Hopsworks\n",
    "8. Launch a serving instance.\n",
    "9. Model deployment in Hopsworks\n",
    "10. Send a prediction request to the served model\n",
    "11. Try out your Model Interactively with a Gradio UI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vVDAHU_bpG4"
   },
   "outputs": [],
   "source": [
    "#!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xRtpj-psbpG8"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVCqQYDhbpG_"
   },
   "source": [
    "## <span style=\"color:#ff5f27;\"> üíΩ Loading the Data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nRmFM7vcbpHA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.read_csv(\"https://repo.hops.works/master/hopsworks-tutorials/data/iris.csv\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JR8HeEs6bpHB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   variety       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2H3XTfhMbpHB"
   },
   "source": [
    "## <span style=\"color:#ff5f27;\"> ü™Ñ Creating Feature Groups </span>\n",
    "\n",
    "We can save two feature groups (hive tables), one called `iris_features` that contains the iris features and the corresponding numeric label, and another feature group called `iris_labels_lookup` for converting the numeric iris label back to categorical.\n",
    "\n",
    "**Note**: To be able to run the feature store code, you first have to enable the Feature Store Service in your project. To do this, go to the \"Settings\" tab in your project, select the feature store service and click \"Save\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/79010\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4By1zTHIbpHC"
   },
   "outputs": [],
   "source": [
    "iris_fg = fs.get_or_create_feature_group(name=\"iris\",\n",
    "                                         version=1,\n",
    "                                         primary_key=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"],\n",
    "                                         description=\"Iris flower dataset\")\n",
    "#iris_fg.insert(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-25 20:07:47,476 INFO: USE `dev_mlops_featurestore`\n",
      "2023-07-25 20:07:47,824 INFO: SELECT `fg0`.`sepal_length` `sepal_length`, `fg0`.`sepal_width` `sepal_width`, `fg0`.`petal_length` `petal_length`, `fg0`.`petal_width` `petal_width`, `fg0`.`variety` `variety`\n",
      "FROM `dev_mlops_featurestore`.`iris_1` `fg0`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.700000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.600000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4.506062</td>\n",
       "      <td>2.919751</td>\n",
       "      <td>3.712156</td>\n",
       "      <td>1.693596</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>4.926606</td>\n",
       "      <td>3.874737</td>\n",
       "      <td>1.950813</td>\n",
       "      <td>0.395821</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>5.581647</td>\n",
       "      <td>3.609850</td>\n",
       "      <td>5.015944</td>\n",
       "      <td>2.053935</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>5.068798</td>\n",
       "      <td>2.726227</td>\n",
       "      <td>4.957020</td>\n",
       "      <td>1.749480</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>5.368180</td>\n",
       "      <td>3.616652</td>\n",
       "      <td>1.264567</td>\n",
       "      <td>0.566253</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     variety\n",
       "0        5.700000     3.800000      1.700000     0.300000      Setosa\n",
       "1        5.600000     2.700000      4.200000     1.300000  Versicolor\n",
       "2        6.300000     3.300000      6.000000     2.500000   Virginica\n",
       "3        5.000000     3.600000      1.400000     0.200000      Setosa\n",
       "4        5.000000     3.000000      1.600000     0.200000      Setosa\n",
       "..            ...          ...           ...          ...         ...\n",
       "151      4.506062     2.919751      3.712156     1.693596  Versicolor\n",
       "152      4.926606     3.874737      1.950813     0.395821      Setosa\n",
       "153      5.581647     3.609850      5.015944     2.053935   Virginica\n",
       "154      5.068798     2.726227      4.957020     1.749480  Versicolor\n",
       "155      5.368180     3.616652      1.264567     0.566253      Setosa\n",
       "\n",
       "[156 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_fg.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n",
    "\n",
    "Feature views are used to read features for training and inference.\n",
    "If the feature view already exists, get it. If not, an exception is thrown, and we create the feature view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2tO8iIb5bpHC"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    feature_view = fs.get_feature_view(name=\"iris\", version=1)\n",
    "except:\n",
    "    # Feature Selection\n",
    "    query = iris_fg.select_all()\n",
    "    feature_view = fs.create_feature_view(name=\"iris\",\n",
    "                                      version=1,\n",
    "                                      description=\"Read from Iris flower dataset\",\n",
    "                                      labels=[\"variety\"],\n",
    "                                      query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "Training dataset is created using `fs.create_train_validation_test_split()` method.\n",
    "\n",
    "* `X_train` is the train set features\n",
    "* `X_val` is the validation set features\n",
    "* `X_test` is the test set features\n",
    "* `Y_train` is the train set labels\n",
    "* `Y_val` is the validation set labels\n",
    "* `Y_test` is the test set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/79010/jobs/named/iris_1_create_fv_td_26072023140258/executions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `2`.\n"
     ]
    }
   ],
   "source": [
    "td_version, td_job = feature_view.create_train_validation_test_split(\n",
    "    description = 'iris tutorial',\n",
    "    data_format = 'csv',\n",
    "    validation_size = 0.2,\n",
    "    test_size = 0.1,\n",
    "    write_options = {'wait_for_job': True},\n",
    "    coalesce = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = feature_view.get_train_validation_test_split(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üß¨ Modeling</span>\n",
    "\n",
    "Train a KNN (k-nearest neighbors) model with Scikit-learn. Use a label encoder to map the categorical labels to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KJb2bj-_bpHD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train['variety'])\n",
    "y_test_encoded = le.transform(y_test['variety'])\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=4)\n",
    "model.fit(X_train, y_train_encoded) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute model performance\n",
    "\n",
    "Compute the MSE of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "b8EC4_SvbpHE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test_encoded, y_pred)\n",
    "\n",
    "metrics = {\n",
    "    \"mse\" : mse\n",
    "}\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üìù Register model</span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where we can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints.\n",
    "\n",
    "Save the following pickled objects as .pkl files locally to a directory that will be uploaded later to the model registry:\n",
    "\n",
    " * the model object, **model** saved as iris_model.pkl\n",
    " * the label encoder object, **le** saved as iris_encoder.pkl, so that we can reconstruct categorical names \n",
    "    from the encoded predictions (numbers) \n",
    "    \n",
    "The model input schema is the same set of features as in the *x_train* DataFrame.\n",
    "\n",
    "The model output schema is the same label as in the *y_train* DataFrame.\n",
    "\n",
    "Finally, lazily create the model that will be register, including all files (artifacts) in the directory (containing the pickled label encoder object and the pickled model object), the model's input/output schema, and a sample input row (**input_example**). The model registry is the **mr** object, and for our Scikit-Learn model, we create a model of type Python with **mr.python.create_model()**. For TensorFlow, there is *mr.tensorflow.create_model()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_model/knn_iris_encoder.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# The 'iris_model' directory will be saved to the model registry\n",
    "model_dir=\"iris_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "    \n",
    "joblib.dump(model, model_dir + '/knn_iris_model.pkl')\n",
    "joblib.dump(le, model_dir + '/knn_iris_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>\n",
    "\n",
    "The model needs to be set up with a [Model Schema](https://docs.hopsworks.ai/machine-learning-api/latest/generated/model_schema/), which describes the inputs and outputs for a model.\n",
    "\n",
    "A Model Schema can be automatically generated from training examples, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ulH3bX02bpHE"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be414b94e8a448d58de9387d2310fc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/79010/models/knn_iris_model_2/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'knn_iris_model_2', version: 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "model_schema.to_dict()\n",
    "\n",
    "iris_model = mr.python.create_model(\n",
    "    name=\"knn_iris_model_2\", \n",
    "    metrics=metrics,\n",
    "    model_schema=model_schema,\n",
    "    input_example=X_train.sample(), \n",
    "    description=\"Iris Flower Predictor\")\n",
    "\n",
    "iris_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">üìé Predictor script for Python models</span>\n",
    "\n",
    "\n",
    "Scikit-learn models are deployed as Python models, in which case you need to provide a **Predict** class that implements the **predict** method. The **predict()** method invokes the model on the inputs and returns the prediction as a list.\n",
    "\n",
    "The **init()** method is run when the predictor is loaded into memory, loading the model from the local directory it is materialized to, *ARTIFACT_FILES_PATH*.\n",
    "\n",
    "The directive \"%%writefile\" writes out the cell before to the given Python file. We will use the **iris_predictor.py** file to create a deployment for our Scikit-Learn K-NN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1k14k_uqbpHF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predict_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_example.py\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "class Predict(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # NOTE: env var ARTIFACT_FILES_PATH has the local path to the model artifact files        \n",
    "        self.model = joblib.load(os.environ[\"ARTIFACT_FILES_PATH\"] + \"/knn_iris_model.pkl\")\n",
    "\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\" Serves a prediction request from a trained model\"\"\"\n",
    "        return self.model.predict(inputs).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"1.5_bullet\" style=\"color:#ff5f27\"> üöÄ Model Deployment</a>\n",
    "\n",
    "Provide the predictor script because it is a Python model (Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zEEHKFzdbpHG"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d093d4684624e748bf7132f9503abb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/417 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/Projects/dev_mlops/Models/predict_example.py'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"predict_example.py\", \"Models\", overwrite=True)\n",
    "predictor_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)\n",
    "predictor_script_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/79010/serving/None). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":120004,\"usrMsg\":\"HTTP 404 Not Found\",\"errorMsg\":\"Web application exception occurred\"}', error code: 120004, error msg: Web application exception occurred, user msg: HTTP 404 Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     deployment \u001b[39m=\u001b[39m ms\u001b[39m.\u001b[39;49mget_deployment(\u001b[39m\"\u001b[39;49m\u001b[39miris_deployed_2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/model_serving.py:86\u001b[0m, in \u001b[0;36mModelServing.get_deployment\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get a deployment by name from Model Serving.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m!!! example\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m    `RestAPIError`: If unable to retrieve deployment from model serving.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_serving_api\u001b[39m.\u001b[39;49mget(name)\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/core/serving_api.py:60\u001b[0m, in \u001b[0;36mServingApi.get\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m query_params \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: name}\n\u001b[0;32m---> 60\u001b[0m deployment_json \u001b[39m=\u001b[39m _client\u001b[39m.\u001b[39;49m_send_request(\n\u001b[1;32m     61\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, path_params, query_params\u001b[39m=\u001b[39;49mquery_params\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m deployment\u001b[39m.\u001b[39mDeployment\u001b[39m.\u001b[39mfrom_response_json(deployment_json)\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[39mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m fn(inst, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/client/base.py:108\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m100\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    110\u001b[0m \u001b[39mif\u001b[39;00m stream:\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/79010/serving). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":240000,\"errorMsg\":\"Serving instance not found\"}', error code: 240000, error msg: Serving instance not found, user msg: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     deployment \u001b[39m=\u001b[39m ms\u001b[39m.\u001b[39mget_deployment(\u001b[39m\"\u001b[39m\u001b[39miris_deployed_2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     deployment \u001b[39m=\u001b[39m iris_model\u001b[39m.\u001b[39;49mdeploy(name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39miris_deployed_2\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m                                    script_file\u001b[39m=\u001b[39;49mpredictor_script_path,  \n\u001b[1;32m      7\u001b[0m                                    \u001b[39m#model_server=\"PYTHON\", \u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m                                    serving_tool\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mKSERVE\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m                                    )\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDeployment: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m deployment\u001b[39m.\u001b[39mname)\n\u001b[1;32m     12\u001b[0m deployment\u001b[39m.\u001b[39mdescribe()\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/model.py:176\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, name, description, artifact_version, serving_tool, script_file, resources, inference_logger, inference_batcher, transformer)\u001b[0m\n\u001b[1;32m    161\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name\n\u001b[1;32m    163\u001b[0m predictor \u001b[39m=\u001b[39m Predictor\u001b[39m.\u001b[39mfor_model(\n\u001b[1;32m    164\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    165\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m     transformer\u001b[39m=\u001b[39mtransformer,\n\u001b[1;32m    174\u001b[0m )\n\u001b[0;32m--> 176\u001b[0m \u001b[39mreturn\u001b[39;00m predictor\u001b[39m.\u001b[39;49mdeploy()\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/predictor.py:121\u001b[0m, in \u001b[0;36mPredictor.deploy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create a deployment for this predictor and persists it in the Model Serving.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \n\u001b[1;32m     92\u001b[0m \u001b[39m!!! example\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m    `Deployment`. The deployment metadata object of a new or existing deployment.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m _deployment \u001b[39m=\u001b[39m deployment\u001b[39m.\u001b[39mDeployment(\n\u001b[1;32m    119\u001b[0m     predictor\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, description\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_description\n\u001b[1;32m    120\u001b[0m )\n\u001b[0;32m--> 121\u001b[0m _deployment\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m    123\u001b[0m \u001b[39mreturn\u001b[39;00m _deployment\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/deployment.py:69\u001b[0m, in \u001b[0;36mDeployment.save\u001b[0;34m(self, await_update)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave\u001b[39m(\u001b[39mself\u001b[39m, await_update: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m60\u001b[39m):\n\u001b[1;32m     61\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Persist this deployment including the predictor and metadata to Model Serving.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[39m    # Arguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m                      the update in the background.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_serving_engine\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, await_update)\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/engine/serving_engine.py:479\u001b[0m, in \u001b[0;36mServingEngine.save\u001b[0;34m(self, deployment_instance, await_update)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave\u001b[39m(\u001b[39mself\u001b[39m, deployment_instance, await_update: \u001b[39mint\u001b[39m):\n\u001b[1;32m    477\u001b[0m     \u001b[39mif\u001b[39;00m deployment_instance\u001b[39m.\u001b[39mid \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[39m# if new deployment\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate(deployment_instance)\n\u001b[1;32m    480\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[39m# if existing deployment\u001b[39;00m\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/engine/serving_engine.py:424\u001b[0m, in \u001b[0;36mServingEngine.create\u001b[0;34m(self, deployment_instance)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPlease, choose a different name.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    422\u001b[0m             \u001b[39mraise\u001b[39;00m re\n\u001b[0;32m--> 424\u001b[0m \u001b[39mif\u001b[39;00m deployment_instance\u001b[39m.\u001b[39;49mis_stopped():\n\u001b[1;32m    425\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBefore making predictions, start the deployment by using `.start()`\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/deployment.py:153\u001b[0m, in \u001b[0;36mDeployment.is_stopped\u001b[0;34m(self, or_created)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_stopped\u001b[39m(\u001b[39mself\u001b[39m, or_created\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    144\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check whether the deployment is stopped\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m \u001b[39m    # Arguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m        `bool`. Whether the deployment is stopped or not.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     status \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_serving_engine\u001b[39m.\u001b[39;49mget_state(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39mstatus\n\u001b[1;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m status \u001b[39m==\u001b[39m PREDICTOR_STATE\u001b[39m.\u001b[39mSTATUS_STOPPED \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    155\u001b[0m         or_created\n\u001b[1;32m    156\u001b[0m         \u001b[39mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         )\n\u001b[1;32m    160\u001b[0m     )\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/engine/serving_engine.py:504\u001b[0m, in \u001b[0;36mServingEngine.get_state\u001b[0;34m(self, deployment_instance)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39merror_code \u001b[39m==\u001b[39m ModelServingException\u001b[39m.\u001b[39mERROR_CODE_SERVING_NOT_FOUND:\n\u001b[1;32m    503\u001b[0m         \u001b[39mraise\u001b[39;00m ModelServingException(\u001b[39m\"\u001b[39m\u001b[39mDeployment not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 504\u001b[0m     \u001b[39mraise\u001b[39;00m re\n\u001b[1;32m    505\u001b[0m deployment_instance\u001b[39m.\u001b[39m_predictor\u001b[39m.\u001b[39m_set_state(state)\n\u001b[1;32m    506\u001b[0m \u001b[39mreturn\u001b[39;00m state\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/engine/serving_engine.py:500\u001b[0m, in \u001b[0;36mServingEngine.get_state\u001b[0;34m(self, deployment_instance)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m(\u001b[39mself\u001b[39m, deployment_instance):\n\u001b[1;32m    499\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 500\u001b[0m         state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_serving_api\u001b[39m.\u001b[39;49mget_state(deployment_instance)\n\u001b[1;32m    501\u001b[0m     \u001b[39mexcept\u001b[39;00m RestAPIError \u001b[39mas\u001b[39;00m re:\n\u001b[1;32m    502\u001b[0m         \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39merror_code \u001b[39m==\u001b[39m ModelServingException\u001b[39m.\u001b[39mERROR_CODE_SERVING_NOT_FOUND:\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/core/serving_api.py:169\u001b[0m, in \u001b[0;36mServingApi.get_state\u001b[0;34m(self, deployment_instance)\u001b[0m\n\u001b[1;32m    162\u001b[0m _client \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mget_instance()\n\u001b[1;32m    163\u001b[0m path_params \u001b[39m=\u001b[39m [\n\u001b[1;32m    164\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mproject\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    165\u001b[0m     _client\u001b[39m.\u001b[39m_project_id,\n\u001b[1;32m    166\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mserving\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    167\u001b[0m     \u001b[39mstr\u001b[39m(deployment_instance\u001b[39m.\u001b[39mid),\n\u001b[1;32m    168\u001b[0m ]\n\u001b[0;32m--> 169\u001b[0m deployment_json \u001b[39m=\u001b[39m _client\u001b[39m.\u001b[39;49m_send_request(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, path_params)\n\u001b[1;32m    170\u001b[0m \u001b[39mreturn\u001b[39;00m predictor_state\u001b[39m.\u001b[39mPredictorState\u001b[39m.\u001b[39mfrom_response_json(deployment_json)\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inst\u001b[39m.\u001b[39m_connected:\n\u001b[1;32m     34\u001b[0m     \u001b[39mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m fn(inst, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/client/base.py:108\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    105\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39msend(prepped, verify\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verify, stream\u001b[39m=\u001b[39mstream)\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m100\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    110\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/79010/serving/None). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":120004,\"usrMsg\":\"HTTP 404 Not Found\",\"errorMsg\":\"Web application exception occurred\"}', error code: 120004, error msg: Web application exception occurred, user msg: HTTP 404 Not Found"
     ]
    }
   ],
   "source": [
    "ms = project.get_model_serving()\n",
    "try:\n",
    "    deployment = ms.get_deployment(\"iris_deployed_2\")\n",
    "except:\n",
    "    deployment = iris_model.deploy(name=\"iris_deployed_2\",\n",
    "                                   script_file=predictor_script_path,  \n",
    "                                   #model_server=\"PYTHON\", \n",
    "                                   serving_tool=\"KSERVE\"\n",
    "                                   )\n",
    "\n",
    "print(\"Deployment: \" + deployment.name)\n",
    "deployment.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The deployment has now been registered. However, to start it you need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7h4qsnUlbpHG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment is already starting\n",
      "{\n",
      "    \"artifact_version\": 1,\n",
      "    \"batching_configuration\": {\n",
      "        \"batching_enabled\": false\n",
      "    },\n",
      "    \"created\": \"2023-07-26T14:13:25.000Z\",\n",
      "    \"creator\": \"David Torres\",\n",
      "    \"description\": null,\n",
      "    \"id\": 52232,\n",
      "    \"inference_logging\": \"NONE\",\n",
      "    \"model_framework\": \"PYTHON\",\n",
      "    \"model_name\": \"knn_iris_model\",\n",
      "    \"model_path\": \"/Projects/dev_mlops/Models/knn_iris_model\",\n",
      "    \"model_server\": \"PYTHON\",\n",
      "    \"model_version\": 1,\n",
      "    \"name\": \"irisdeployed\",\n",
      "    \"predictor\": \"predict_example.py\",\n",
      "    \"predictor_resources\": {\n",
      "        \"limits\": {\n",
      "            \"cores\": 0.5,\n",
      "            \"gpus\": 0,\n",
      "            \"memory\": 1024\n",
      "        },\n",
      "        \"requests\": {\n",
      "            \"cores\": 0.2,\n",
      "            \"gpus\": 0,\n",
      "            \"memory\": 32\n",
      "        }\n",
      "    },\n",
      "    \"requested_instances\": 0,\n",
      "    \"serving_tool\": \"KSERVE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "state = deployment.get_state()\n",
    "\n",
    "if state.status != \"Running\":\n",
    "    deployment.start()\n",
    "    deployment.describe()\n",
    "else:\n",
    "    print(\"Deployment already running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment is starting, server logs might not be ready yet\n",
      "Explore all the logs and filters in the Kibana logs at https://c.app.hopsworks.ai:443/p/79010/deployments/52232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deployment.get_logs(component='predictor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0iRFs0FbpHH"
   },
   "source": [
    "## <span style='color:#ff5f27'>üîÆ Predicting using deployment</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ICAE38pzbpHH"
   },
   "outputs": [
    {
     "ename": "ModelServingException",
     "evalue": "Deployment not created or running. If it is already created, start it by using `.start()` or check its status with .get_state()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/engine/serving_engine.py:186\u001b[0m, in \u001b[0;36mServingEngine.predict\u001b[0;34m(self, deployment_instance, data, inputs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_serving_api\u001b[39m.\u001b[39;49msend_inference_request(\n\u001b[1;32m    187\u001b[0m         deployment_instance, payload, through_hopsworks\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m RestAPIError \u001b[39mas\u001b[39;00m re:\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/core/serving_api.py:229\u001b[0m, in \u001b[0;36mServingApi.send_inference_request\u001b[0;34m(self, deployment_instance, data, through_hopsworks)\u001b[0m\n\u001b[1;32m    226\u001b[0m         path_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_hopsworks_inference_path(\n\u001b[1;32m    227\u001b[0m             _client\u001b[39m.\u001b[39m_project_id, deployment_instance\n\u001b[1;32m    228\u001b[0m         )\n\u001b[0;32m--> 229\u001b[0m \u001b[39mreturn\u001b[39;00m _client\u001b[39m.\u001b[39;49m_send_request(\n\u001b[1;32m    230\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, path_params, headers\u001b[39m=\u001b[39;49mheaders, data\u001b[39m=\u001b[39;49mjson\u001b[39m.\u001b[39;49mdumps(data)\n\u001b[1;32m    231\u001b[0m )\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[39mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m fn(inst, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/client/base.py:108\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m100\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    110\u001b[0m \u001b[39mif\u001b[39;00m stream:\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: http://acfdd5a4a839249e8bb85d8b9651a20b-928877002.us-east-2.elb.amazonaws.com/v1/models/irisdeployed:predict). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModelServingException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m test_data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(iris_model\u001b[39m.\u001b[39minput_example)\n\u001b[1;32m      3\u001b[0m data \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39minstances\u001b[39m\u001b[39m\"\u001b[39m : [test_data]}\n\u001b[0;32m----> 4\u001b[0m res \u001b[39m=\u001b[39m deployment\u001b[39m.\u001b[39;49mpredict(data)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(test_data)\n\u001b[1;32m      6\u001b[0m \u001b[39m#print(le.inverse_transform([res[\"predictions\"][0]]))\u001b[39;00m\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/deployment.py:196\u001b[0m, in \u001b[0;36mDeployment.predict\u001b[0;34m(self, data, inputs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, data: \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, inputs: \u001b[39mlist\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    163\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Send inference requests to the deployment.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m       One of data or inputs parameters must be set. If both are set, inputs will be ignored.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39m        `dict`. Inference response.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_serving_engine\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m, data, inputs)\n",
      "File \u001b[0;32m~/learnings/serveless/serverless-ml-course/venv/lib/python3.8/site-packages/hsml/engine/serving_engine.py:195\u001b[0m, in \u001b[0;36mServingEngine.predict\u001b[0;34m(self, deployment_instance, data, inputs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m RestAPIError \u001b[39mas\u001b[39;00m re:\n\u001b[1;32m    190\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    191\u001b[0m         re\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m RestAPIError\u001b[39m.\u001b[39mSTATUS_CODE_NOT_FOUND\n\u001b[1;32m    192\u001b[0m         \u001b[39mor\u001b[39;00m re\u001b[39m.\u001b[39merror_code\n\u001b[1;32m    193\u001b[0m         \u001b[39m==\u001b[39m ModelServingException\u001b[39m.\u001b[39mERROR_CODE_DEPLOYMENT_NOT_RUNNING\n\u001b[1;32m    194\u001b[0m     ):\n\u001b[0;32m--> 195\u001b[0m         \u001b[39mraise\u001b[39;00m ModelServingException(\n\u001b[1;32m    196\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mDeployment not created or running. If it is already created, start it by using `.start()` or check its status with .get_state()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     re\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m (\n\u001b[1;32m    200\u001b[0m         re\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m Check the model server logs by using `.get_logs()`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m     )\n\u001b[1;32m    202\u001b[0m     \u001b[39mraise\u001b[39;00m re\n",
      "\u001b[0;31mModelServingException\u001b[0m: Deployment not created or running. If it is already created, start it by using `.start()` or check its status with .get_state()"
     ]
    }
   ],
   "source": [
    "test_data = list(iris_model.input_example)\n",
    "\n",
    "data = {\"instances\" : [test_data]}\n",
    "res = deployment.predict(data)\n",
    "print(test_data)\n",
    "#print(le.inverse_transform([res[\"predictions\"][0]]))\n",
    "print([res[\"predictions\"][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSFCgRWcbpHH"
   },
   "source": [
    "## <span style=\"color:#ff5f27;\"> üëæ Try out your Model Interactively </span> \n",
    "\n",
    "\n",
    "We will build a user interface with Gradio to allow you to enter the 4 feature values (sepal length/width and petal length/width), producing a prediction of the type of iris flower.\n",
    "\n",
    "First, we have to install the gradio library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdMNftbQbpHI"
   },
   "outputs": [],
   "source": [
    "#!pip install gradio --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Gradio\n",
    "\n",
    "Start the Gradio UI. Users enter the 4 feature values and a prediction is returned. We use the label encoder object to transform the number returned to the categorical value (stringified name of the Iris Flower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3DyKEOLbpHI"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def iris(sl, sw, pl, pw):\n",
    "    list_inputs = []\n",
    "    list_inputs.append(sl)\n",
    "    list_inputs.append(sw)\n",
    "    list_inputs.append(pl)\n",
    "    list_inputs.append(pw)\n",
    "    data = {\n",
    "        \"instances\": [list_inputs]\n",
    "    }\n",
    "    res = deployment.predict(data)\n",
    "    # Convert the numerical representation of the label back to it's original iris flower name.\n",
    "    return le.inverse_transform([res[\"predictions\"][0]])[0]\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=iris,\n",
    "    title=\"Iris Flower Predictive Analytics\",\n",
    "    description=\"Experiment with sepal/petal lengths/widths to predict which flower it is.\",\n",
    "    allow_flagging=\"never\",\n",
    "    inputs=[\n",
    "        gr.inputs.Number(default=1.0, label=\"sepal length (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"sepal width (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"petal length (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"petal width (cm)\"),\n",
    "        ],\n",
    "    outputs=\"text\")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6trMW766bpHJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "August 2022 iris_sklearn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
